name: "run_benchmark"
namespace: "workflows"
argument_groups:
  - name: Inputs
    arguments:
      - name: "--input_spatial_dataset"
        __merge__: ../../api/file_dataset_sp.yaml
        direction: input
        required: true
      - name: "--input_singlecell_dataset"
        __merge__: ../../api/file_dataset_sc.yaml
        direction: input
        required: true
      # - name: "--input_simulated_dataset"
      #   __merge__: ../../api/file_simulated_dataset.yaml
      #   direction: input
      #   required: true
  - name: Outputs
    arguments:
      - name: "--output_scores"
        type: file
        required: true
        direction: output
        description: A yaml file containing the scores of each of the methods
        default: score_uns.yaml
      - name: "--output_method_configs"
        type: file
        required: true
        direction: output
        default: method_configs.yaml
      - name: "--output_metric_configs"
        type: file
        required: true
        direction: output
        default: metric_configs.yaml
      - name: "--output_dataset_info"
        type: file
        required: true
        direction: output
        default: dataset_uns.yaml
      - name: "--output_task_info"
        type: file
        required: true
        direction: output
        default: task_info.yaml
resources:
  - type: nextflow_script
    path: main.nf
    entrypoint: run_wf
  - type: file
    path: "../../api/task_info.yaml"
dependencies:
  - name: common/check_dataset_schema
    repository: openproblems_v2
  - name: common/extract_metadata
    repository: openproblems_v2
  - name: methods/scdesign2
  - name: methods/scdesign3
  - name: methods/sparsim
  - name: methods/splatter
  - name: methods/srtsim
  - name: methods/symsim
  - name: methods/zinbwave
  - name: metrics/ks_statistic_gene_cell
runners:
  - type: nextflow